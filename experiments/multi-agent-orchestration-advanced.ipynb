{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ee30ab-7efb-46f2-a9f2-768a526afaad",
   "metadata": {},
   "source": [
    "# Doppel Multi Agent Orchestration Experiments - Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3713be7d-d332-48bf-8255-ee3c0b4a7a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from enum import IntEnum\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from profiles import candidate_profile, recruiter_profile\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4467e4",
   "metadata": {},
   "source": [
    "Thinking Levels are layers of reasoning and planning. Simple tasks do not require higher levels of thinking unlike complex tasks. Higher thinking levels are more expensive as a result of the complexity of the task.\n",
    "\n",
    "- Execution does not require thinking.\n",
    "- Tactical thinking is thinking about how to accomplish a task. \n",
    "- Looks at the big picture and the overall strategy.\n",
    "- Monitors performance, identifies patterns in failures/successes, adapts strategies. Like a human evaluating their own thoughts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f0108f-76f6-4e0a-8050-090683b7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThinkingLevel(IntEnum):\n",
    "    EXECUTION = 1\n",
    "    TACTICAL = 2\n",
    "    STRATEGIC = 3\n",
    "    META_COGNITIVE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf42a3",
   "metadata": {},
   "source": [
    "Thought Signatures allow the some notes that agent writes for itself. Similar to a human writing notes in a notebook. This makes sure that the agent knows what the original ask was and how it is progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c199ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ThoughtSignature:\n",
    "    thinking_level: ThinkingLevel\n",
    "    what_learned: str\n",
    "    goal_progress: Dict[str, bool]\n",
    "    match_confidence: int\n",
    "    next_action: str\n",
    "    self_correction: Optional[str] = None\n",
    "    should_conclude: bool = False\n",
    "    critical_mismatch: bool = False\n",
    "    cost: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991a4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConversationContext:\n",
    "    turn_number: int\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    last_response: str\n",
    "    remaining_goals: List[str]\n",
    "    current_confidence: int\n",
    "    previous_confidence: int = 50\n",
    "    is_opening: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b80201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThinkingLevelManager:\n",
    "    def __init__(self, llm: ChatGoogleGenerativeAI):\n",
    "        self.llm = llm\n",
    "\n",
    "    def determine_level(self, context: ConversationContext) -> ThinkingLevel:\n",
    "        if context.is_opening:\n",
    "            return ThinkingLevel.EXECUTION\n",
    "\n",
    "        if not context.last_response:\n",
    "            return ThinkingLevel.EXECUTION\n",
    "\n",
    "        confidence_delta = abs(context.current_confidence - context.previous_confidence)\n",
    "\n",
    "        if confidence_delta >= 25:\n",
    "            return ThinkingLevel.STRATEGIC\n",
    "\n",
    "        if len(context.remaining_goals) <= 2 and context.current_confidence >= 80:\n",
    "            return ThinkingLevel.STRATEGIC\n",
    "\n",
    "        response_length = len(context.last_response.split())\n",
    "        if response_length < 15:\n",
    "            return ThinkingLevel.TACTICAL\n",
    "\n",
    "        if context.turn_number >= 6:\n",
    "            return ThinkingLevel.STRATEGIC\n",
    "\n",
    "        return ThinkingLevel.TACTICAL\n",
    "\n",
    "    async def think(\n",
    "        self,\n",
    "        level: ThinkingLevel,\n",
    "        context: ConversationContext,\n",
    "        goal_progress: Dict[str, bool],\n",
    "        criteria: List[str],\n",
    "    ) -> ThoughtSignature:\n",
    "        if level == ThinkingLevel.EXECUTION:\n",
    "            return self._execute_routine(context, goal_progress)\n",
    "        elif level == ThinkingLevel.TACTICAL:\n",
    "            return await self._tactical_thinking(context, goal_progress, criteria)\n",
    "        elif level == ThinkingLevel.STRATEGIC:\n",
    "            return await self._strategic_thinking(context, goal_progress, criteria)\n",
    "        else:\n",
    "            return await self._meta_cognitive_thinking(context, goal_progress, criteria)\n",
    "\n",
    "    def _execute_routine(\n",
    "        self, context: ConversationContext, goal_progress: Dict[str, bool]\n",
    "    ) -> ThoughtSignature:\n",
    "        return ThoughtSignature(\n",
    "            thinking_level=ThinkingLevel.EXECUTION,\n",
    "            what_learned=\"Opening conversation - gathering initial information\",\n",
    "            goal_progress=goal_progress,\n",
    "            match_confidence=context.current_confidence,\n",
    "            next_action=\"Ask opening question about their background\",\n",
    "        )\n",
    "\n",
    "    async def _tactical_thinking(\n",
    "        self,\n",
    "        context: ConversationContext,\n",
    "        goal_progress: Dict[str, bool],\n",
    "    ) -> ThoughtSignature:\n",
    "        unverified = [c for c, verified in goal_progress.items() if not verified]\n",
    "        prompt = f\"\"\"You are analyzing a candidate's response in a recruiting conversation.\n",
    "\n",
    "Response to analyze: \"{context.last_response}\"\n",
    "\n",
    "Unverified criteria: {unverified[:3]}\n",
    "\n",
    "Provide a brief tactical analysis in JSON format:\n",
    "{{\n",
    "    \"what_learned\": \"1-2 sentence summary of what this response reveals\",\n",
    "    \"criteria_updates\": {{\"criterion text\": true/false}},\n",
    "    \"confidence_adjustment\": number between -15 and +15,\n",
    "    \"next_action\": \"specific next question or topic to probe\",\n",
    "    \"needs_clarification\": true/false\n",
    "}}\n",
    "\n",
    "Be concise. Only mark criteria as true if clearly demonstrated.\"\"\"\n",
    "\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = await self.llm.ainvoke(messages)\n",
    "        content = self._extract_text(response.content)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(self._clean_json(content))\n",
    "        except json.JSONDecodeError:\n",
    "            data = {\n",
    "                \"what_learned\": \"Response received, continuing assessment\",\n",
    "                \"criteria_updates\": {},\n",
    "                \"confidence_adjustment\": 0,\n",
    "                \"next_action\": \"Continue probing relevant skills\",\n",
    "                \"needs_clarification\": False,\n",
    "            }\n",
    "\n",
    "        new_progress = goal_progress.copy()\n",
    "        for criterion, verified in data.get(\"criteria_updates\", {}).items():\n",
    "            if criterion in new_progress:\n",
    "                new_progress[criterion] = verified\n",
    "\n",
    "        new_confidence = max(\n",
    "            0, min(100, context.current_confidence + data.get(\"confidence_adjustment\", 0))\n",
    "        )\n",
    "\n",
    "        return ThoughtSignature(\n",
    "            thinking_level=ThinkingLevel.TACTICAL,\n",
    "            what_learned=data.get(\"what_learned\", \"\"),\n",
    "            goal_progress=new_progress,\n",
    "            match_confidence=new_confidence,\n",
    "            next_action=data.get(\"next_action\", \"\"),\n",
    "        )\n",
    "\n",
    "    async def _strategic_thinking(\n",
    "        self,\n",
    "        context: ConversationContext,\n",
    "        goal_progress: Dict[str, bool],\n",
    "    ) -> ThoughtSignature:\n",
    "        verified_count = sum(1 for v in goal_progress.values() if v)\n",
    "        total_count = len(goal_progress)\n",
    "        history_summary = \"\\n\".join(\n",
    "            [f\"{m['role']}: {m['content'][:100]}...\" for m in context.conversation_history[-4:]]\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"You are conducting a strategic reassessment of a recruiting conversation.\n",
    "\n",
    "Recent conversation:\n",
    "{history_summary}\n",
    "\n",
    "Latest response: \"{context.last_response}\"\n",
    "\n",
    "Progress: {verified_count}/{total_count} criteria verified\n",
    "Current confidence: {context.current_confidence}%\n",
    "Turn number: {context.turn_number}\n",
    "\n",
    "Provide strategic analysis in JSON format:\n",
    "{{\n",
    "    \"what_learned\": \"key insight from this conversation stage\",\n",
    "    \"criteria_updates\": {{\"criterion text\": true/false}},\n",
    "    \"confidence_adjustment\": number between -25 and +25,\n",
    "    \"self_correction\": \"any strategic pivot needed (or null)\",\n",
    "    \"next_action\": \"strategic next move\",\n",
    "    \"should_conclude\": true/false,\n",
    "    \"critical_mismatch\": true/false\n",
    "}}\n",
    "\n",
    "Consider: Is this candidate stronger/weaker than expected? Should we pivot strategy?\"\"\"\n",
    "\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = await self.llm.ainvoke(messages)\n",
    "        content = self._extract_text(response.content)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(self._clean_json(content))\n",
    "        except json.JSONDecodeError:\n",
    "            data = {\n",
    "                \"what_learned\": \"Strategic assessment in progress\",\n",
    "                \"criteria_updates\": {},\n",
    "                \"confidence_adjustment\": 0,\n",
    "                \"self_correction\": None,\n",
    "                \"next_action\": \"Continue strategic assessment\",\n",
    "                \"should_conclude\": False,\n",
    "                \"critical_mismatch\": False,\n",
    "            }\n",
    "\n",
    "        new_progress = goal_progress.copy()\n",
    "        for criterion, verified in data.get(\"criteria_updates\", {}).items():\n",
    "            if criterion in new_progress:\n",
    "                new_progress[criterion] = verified\n",
    "\n",
    "        new_confidence = max(\n",
    "            0, min(100, context.current_confidence + data.get(\"confidence_adjustment\", 0))\n",
    "        )\n",
    "\n",
    "        return ThoughtSignature(\n",
    "            thinking_level=ThinkingLevel.STRATEGIC,\n",
    "            what_learned=data.get(\"what_learned\", \"\"),\n",
    "            goal_progress=new_progress,\n",
    "            match_confidence=new_confidence,\n",
    "            next_action=data.get(\"next_action\", \"\"),\n",
    "            self_correction=data.get(\"self_correction\"),\n",
    "            should_conclude=data.get(\"should_conclude\", False),\n",
    "            critical_mismatch=data.get(\"critical_mismatch\", False),\n",
    "        )\n",
    "\n",
    "    async def _meta_cognitive_thinking(\n",
    "        self,\n",
    "        context: ConversationContext,\n",
    "        goal_progress: Dict[str, bool],\n",
    "    ) -> ThoughtSignature:\n",
    "        history_summary = \"\\n\".join(\n",
    "            [f\"{m['role']}: {m['content']}\" for m in context.conversation_history]\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"You are conducting deep meta-cognitive reflection on a recruiting conversation.\n",
    "\n",
    "Full conversation:\n",
    "{history_summary}\n",
    "\n",
    "Latest response: \"{context.last_response}\"\n",
    "\n",
    "Current assessment:\n",
    "- Verified criteria: {[c for c, v in goal_progress.items() if v]}\n",
    "- Unverified: {[c for c, v in goal_progress.items() if not v]}\n",
    "- Confidence: {context.current_confidence}%\n",
    "\n",
    "Provide deep reflection in JSON format:\n",
    "{{\n",
    "    \"what_learned\": \"fundamental insight about this candidate/conversation\",\n",
    "    \"criteria_updates\": {{\"criterion text\": true/false}},\n",
    "    \"confidence_adjustment\": number between -40 and +40,\n",
    "    \"self_correction\": \"critical reframing of approach (if needed)\",\n",
    "    \"next_action\": \"final action to take\",\n",
    "    \"should_conclude\": true/false,\n",
    "    \"critical_mismatch\": true/false,\n",
    "    \"learning_for_future\": \"pattern to remember for future conversations\"\n",
    "}}\n",
    "\n",
    "This is expensive thinking - provide deep, actionable insights.\"\"\"\n",
    "\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = await self.llm.ainvoke(messages)\n",
    "        content = self._extract_text(response.content)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(self._clean_json(content))\n",
    "        except json.JSONDecodeError:\n",
    "            data = {\n",
    "                \"what_learned\": \"Deep reflection completed\",\n",
    "                \"criteria_updates\": {},\n",
    "                \"confidence_adjustment\": 0,\n",
    "                \"self_correction\": None,\n",
    "                \"next_action\": \"Conclude conversation\",\n",
    "                \"should_conclude\": True,\n",
    "                \"critical_mismatch\": False,\n",
    "            }\n",
    "\n",
    "        new_progress = goal_progress.copy()\n",
    "        for criterion, verified in data.get(\"criteria_updates\", {}).items():\n",
    "            if criterion in new_progress:\n",
    "                new_progress[criterion] = verified\n",
    "\n",
    "        new_confidence = max(\n",
    "            0, min(100, context.current_confidence + data.get(\"confidence_adjustment\", 0))\n",
    "        )\n",
    "\n",
    "        return ThoughtSignature(\n",
    "            thinking_level=ThinkingLevel.META_COGNITIVE,\n",
    "            what_learned=data.get(\"what_learned\", \"\"),\n",
    "            goal_progress=new_progress,\n",
    "            match_confidence=new_confidence,\n",
    "            next_action=data.get(\"next_action\", \"\"),\n",
    "            self_correction=data.get(\"self_correction\"),\n",
    "            should_conclude=data.get(\"should_conclude\", True),\n",
    "            critical_mismatch=data.get(\"critical_mismatch\", False),\n",
    "        )\n",
    "\n",
    "    def _extract_text(self, content) -> str:\n",
    "        if isinstance(content, list):\n",
    "            parts = []\n",
    "            for part in content:\n",
    "                if isinstance(part, dict) and \"text\" in part:\n",
    "                    parts.append(part[\"text\"])\n",
    "                elif isinstance(part, str):\n",
    "                    parts.append(part)\n",
    "            return \" \".join(parts)\n",
    "        return str(content)\n",
    "\n",
    "    def _clean_json(self, text: str) -> str:\n",
    "        text = text.strip()\n",
    "        if text.startswith(\"```json\"):\n",
    "            text = text[7:]\n",
    "        if text.startswith(\"```\"):\n",
    "            text = text[3:]\n",
    "        if text.endswith(\"```\"):\n",
    "            text = text[:-3]\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df1ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "        temperature=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92808f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class RecruiterResponse(BaseModel):\n",
    "    response: str = Field(description=\"The response to the candidate's last message.\")\n",
    "    is_final_response: bool = Field(\n",
    "        description=\"Whether this is the final response in the conversation. Set to true after 6-10 exchanges or when you have enough information.\"\n",
    "    )\n",
    "    final_evaluation: str = Field(\n",
    "        description=\"The final evaluation of the candidate. Only populated if is_final_response is true. Format: ✓/✗ for each criterion with brief evidence, Rating: X/10, Decision: GOOD FIT or NOT A FIT with reasoning.\",\n",
    "        default=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b212b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecruiterAgent:\n",
    "    def __init__(self, profile: dict, llm: ChatGoogleGenerativeAI):\n",
    "        self.profile = profile\n",
    "        self.llm = llm\n",
    "        self.name = profile[\"name\"]\n",
    "        self.criteria = profile[\"candidate_selection_criteria\"]\n",
    "        \n",
    "        self.structured_llm = self.llm.with_structured_output(RecruiterResponse)\n",
    "        \n",
    "        self._build_system_prompt()\n",
    "\n",
    "    def _build_system_prompt(self):\n",
    "        criteria_list = \"\\n\".join(\n",
    "            [f\"{i + 1}. {criterion}\" for i, criterion in enumerate(self.criteria)]\n",
    "        )\n",
    "\n",
    "        self.system_prompt = f\"\"\"You are {self.profile[\"name\"]}, {self.profile[\"bio\"]}\n",
    "\n",
    "You're at a networking event having a casual conversation with a candidate. Keep it brief, natural, and conversational - like a quick chat at a career fair.\n",
    "\n",
    "Job Description: {self.profile[\"job_description\"]}\n",
    "\n",
    "Selection Criteria (mentally check off as you learn):\n",
    "{criteria_list}\n",
    "\n",
    "Guidelines:\n",
    "- Keep responses SHORT (2-4 sentences max for questions, 1-2 sentences for follow-ups)\n",
    "- Ask one question at a time\n",
    "- Be friendly but direct - no long explanations\n",
    "- After 6-10 exchanges, set is_final_response to true and provide evaluation\n",
    "- Final evaluation format:\n",
    "  ✓/✗ for each criterion with brief evidence\n",
    "  Rating: X/10\n",
    "  Decision: GOOD FIT or NOT A FIT with 2-3 sentence reasoning\n",
    "\n",
    "Keep it natural and brief - this is a quick networking chat, not a formal interview.\"\"\"\n",
    "\n",
    "    def _build_conversation_context(self, conversation_history: List[Dict[str, str]]) -> str:\n",
    "        if not conversation_history:\n",
    "            return \"No conversation yet. Start with a friendly greeting.\"\n",
    "        \n",
    "        conversation_text = \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\" \n",
    "            for msg in conversation_history\n",
    "        ])\n",
    "        \n",
    "        return f\"Conversation so far:\\n{conversation_text}\"\n",
    "\n",
    "    async def respond(self, conversation_history: List[Dict[str, str]]) -> RecruiterResponse:\n",
    "        messages = [SystemMessage(content=self.system_prompt)]\n",
    "        \n",
    "        context = self._build_conversation_context(conversation_history)\n",
    "        \n",
    "        messages.append(HumanMessage(content=context + \"\\n\\nYour response:\"))\n",
    "        \n",
    "        response: RecruiterResponse = await self.structured_llm.ainvoke(messages)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1a884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateAgent:\n",
    "    def __init__(self, profile: dict, llm: ChatGoogleGenerativeAI):\n",
    "        self.profile = profile\n",
    "        self.llm = llm\n",
    "        self.name = profile[\"personal_info\"][\"full_name\"]\n",
    "        self._build_system_prompt()\n",
    "\n",
    "    def _build_system_prompt(self):\n",
    "        profile_json = json.dumps(self.profile, indent=2)\n",
    "\n",
    "        self.system_prompt = f\"\"\"You are {self.profile[\"personal_info\"][\"full_name\"]} at a networking event.\n",
    "\n",
    "Your profile:\n",
    "{profile_json}\n",
    "\n",
    "Guidelines:\n",
    "- Keep responses SHORT (2-3 sentences max)\n",
    "- Be natural and conversational - like talking to someone at a career fair\n",
    "- Answer questions directly, reference your actual experience when relevant\n",
    "- If you don't have experience with something, briefly say so and mention related skills\n",
    "- Don't over-explain or be verbose\n",
    "- Stay authentic to your profile above\n",
    "\n",
    "This is a quick networking chat, not a formal interview. Keep it brief and natural.\"\"\"\n",
    "\n",
    "    def _build_conversation_context(self, conversation_history: List[Dict[str, str]]) -> str:\n",
    "        if not conversation_history:\n",
    "            return \"No conversation yet.\"\n",
    "        \n",
    "        conversation_text = \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\" \n",
    "            for msg in conversation_history\n",
    "        ])\n",
    "        \n",
    "        return f\"Conversation so far:\\n{conversation_text}\"\n",
    "\n",
    "    async def respond(self, conversation_history: List[Dict[str, str]]) -> str:\n",
    "        messages = [SystemMessage(content=self.system_prompt)]\n",
    "        \n",
    "        context = self._build_conversation_context(conversation_history)\n",
    "        \n",
    "        messages.append(HumanMessage(content=context + \"\\n\\nYour response:\"))\n",
    "        \n",
    "        response = await self.llm.ainvoke(messages)\n",
    "        return self._extract_text(response.content)\n",
    "\n",
    "    def _extract_text(self, content) -> str:\n",
    "        if isinstance(content, list):\n",
    "            parts = []\n",
    "            for part in content:\n",
    "                if isinstance(part, dict) and \"text\" in part:\n",
    "                    parts.append(part[\"text\"])\n",
    "                elif isinstance(part, str):\n",
    "                    parts.append(part)\n",
    "            return \" \".join(parts) if parts else str(content)\n",
    "        return str(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "134c395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationOrchestrator:\n",
    "    def __init__(self, recruiter: RecruiterAgent, candidate: CandidateAgent):\n",
    "        self.recruiter = recruiter\n",
    "        self.candidate = candidate\n",
    "        self.conversation_history: List[Dict[str, str]] = []\n",
    "\n",
    "    def _print_message(self, speaker: str, role: str, message: str):\n",
    "        print(f\"\\n[{speaker} - {role}]: {message}\\n\")\n",
    "\n",
    "    async def run_conversation(self, max_turns: int = 12) -> Dict[str, Any]:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"NETWORKING SESSION - SCREENING CONVERSATION\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "\n",
    "        turn_count = 0\n",
    "        \n",
    "        recruiter_response = await self.recruiter.respond(self.conversation_history)\n",
    "        \n",
    "        if recruiter_response.is_final_response:\n",
    "            self._print_message(self.recruiter.name, \"Recruiter\", recruiter_response.response)\n",
    "            print(f\"\\n{recruiter_response.final_evaluation}\")\n",
    "            return self._build_result(recruiter_response.final_evaluation)\n",
    "        \n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"recruiter\", \n",
    "            \"content\": recruiter_response.response\n",
    "        })\n",
    "        self._print_message(self.recruiter.name, \"Recruiter\", recruiter_response.response)\n",
    "\n",
    "        while turn_count < max_turns:\n",
    "            candidate_response = await self.candidate.respond(self.conversation_history)\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"candidate\",\n",
    "                \"content\": candidate_response\n",
    "            })\n",
    "            self._print_message(self.candidate.name, \"Candidate\", candidate_response)\n",
    "            turn_count += 1\n",
    "\n",
    "            recruiter_response = await self.recruiter.respond(self.conversation_history)\n",
    "            \n",
    "            if recruiter_response.is_final_response:\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"recruiter\",\n",
    "                    \"content\": recruiter_response.response\n",
    "                })\n",
    "                self._print_message(self.recruiter.name, \"Recruiter\", recruiter_response.response)\n",
    "                print(f\"\\n{recruiter_response.final_evaluation}\")\n",
    "                break\n",
    "            \n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"recruiter\",\n",
    "                \"content\": recruiter_response.response\n",
    "            })\n",
    "            self._print_message(self.recruiter.name, \"Recruiter\", recruiter_response.response)\n",
    "\n",
    "        if not recruiter_response.is_final_response:\n",
    "            print(\"\\n[Max turns reached - requesting final evaluation]\")\n",
    "\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Please provide your final evaluation now.\"\n",
    "            })\n",
    "            \n",
    "            final_response = await self.recruiter.respond(self.conversation_history)\n",
    "            self._print_message(self.recruiter.name, \"Recruiter\", final_response.response)\n",
    "            if final_response.final_evaluation:\n",
    "                print(f\"\\n{final_response.final_evaluation}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONVERSATION COMPLETE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self._build_result(recruiter_response.final_evaluation)\n",
    "\n",
    "    def _build_result(self, final_evaluation: str) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"conversation_history\": self.conversation_history,\n",
    "            \"final_evaluation\": final_evaluation,\n",
    "            \"total_turns\": len([msg for msg in self.conversation_history if msg[\"role\"] == \"candidate\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20cc2111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NETWORKING SESSION - SCREENING CONVERSATION\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: Hey there! I'm Brodie, I focus on Platform Technology and RBCx digital solutions here at RBC. What kind of development work have you been focusing on lately, maybe specifically within the PHP or WordPress space?\n",
      "\n",
      "\n",
      "[Aryan Khurana - Candidate]: Nice to meet you, Brodie! I’m actually on the AI team here at RBC right now, focusing on building multi-agent systems and intelligent automation with FastAPI. While I have intermediate experience with PHP, I’ve been leaning more into custom AI architectures and scalable backend solutions lately rather than the WordPress space.\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: That AI work sounds fascinating, especially with FastAPI. For this specific role at RBCx, we’re really focused on the intersection of high-scale WordPress VIP and frontend excellence. How much experience do you have translating Figma designs into responsive, WCAG-compliant interfaces?\n",
      "\n",
      "\n",
      "[Aryan Khurana - Candidate]: I use Figma regularly to architect the UI for my projects like Rezzy and Viralens before building them out in React or Vue. I'm very comfortable translating designs into responsive, production-ready interfaces, and I always prioritize accessibility and modern web standards in my frontend work.\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: Good to hear you're comfortable with Figma and accessibility. Since this role is heavily centered on WordPress VIP, have you worked with high-scale PHP architectures or custom VIP-compatible themes before?\n",
      "\n",
      "\n",
      "[Aryan Khurana - Candidate]: I haven't worked with WordPress VIP specifically, but I have a solid foundation in PHP from building custom full-stack solutions. Most of my recent high-scale architecture work has focused on FastAPI and MongoDB for my SaaS projects and enterprise AI systems here at RBC.\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: I appreciate the transparency on the VIP side. Since the RBCx team relies heavily on Git, Jenkins, and CI/CD for our deployments, how have you integrated those DevOps practices into your current AI or SaaS workflows?\n",
      "\n",
      "\n",
      "[Aryan Khurana - Candidate]: I use Git and GitHub Actions daily to manage automated deployments for my SaaS projects like Rezzy. At RBC, I'm already well-integrated into our enterprise CI/CD pipelines, using Jenkins and Docker to ensure our AI services are stable and production-ready.\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: That's a huge plus that you're already familiar with our enterprise Jenkins and Docker environment. Since we use Tailwind CSS heavily for our frontend architecture, have you worked with that much, and how do you usually handle troubleshooting RESTful API integrations?\n",
      "\n",
      "\n",
      "[Aryan Khurana - Candidate]: I used Tailwind CSS to build out the entire frontend for Rezzy, so I’m very comfortable with that utility-first approach. For troubleshooting APIs, I typically use Postman for manual testing and set up detailed logging in FastAPI to quickly isolate any issues in the data flow.\n",
      "\n",
      "\n",
      "[Brodie Moss - Recruiter]: I really appreciate the insight into your background; you've clearly got a strong technical foundation in AI and modern frontend tools. While your DevOps and Tailwind skills are spot on, we're specifically looking for deep expertise in WordPress VIP and high-scale PHP for this particular squad.\n",
      "\n",
      "\n",
      "1. Minimum 4 years PHP/JS/WP VIP: ✗ (Intermediate PHP, no VIP experience)\n",
      "2. Figma/Tailwind: ✓ (Regularly uses Figma and built Rezzy with Tailwind)\n",
      "3. WCAG AA: ✓ (Prioritizes accessibility and modern standards)\n",
      "4. RESTful API: ✓ (Uses Postman and logging for troubleshooting)\n",
      "5. DevOps: ✓ (Already using RBC's Jenkins/Docker/Git pipelines)\n",
      "6. UI/UX Translation: ✓ (Architects UI in Figma before building)\n",
      "7. Clean code: ✓ (Follows best practices in enterprise environment)\n",
      "8. Problem-solving: ✓ (Strategic approach to API data flow)\n",
      "9. Reusable PHP templates: ✗ (Focus is on React/Vue/FastAPI)\n",
      "10. CRM: ? (Not confirmed)\n",
      "11. Collaborative: ✓ (Currently working on RBC AI team)\n",
      "12. Passion: ✓ (Active in building side projects like Rezzy and Viralens)\n",
      "\n",
      "Rating: 6/10\n",
      "Decision: NOT A FIT. While the candidate is a highly skilled engineer with excellent DevOps and frontend experience, they lack the specific deep expertise in WordPress VIP and high-scale PHP required for this role. Their current trajectory in AI and FastAPI makes them a better fit for other RBC Platform roles rather than this specific WordPress-centric position.\n",
      "\n",
      "================================================================================\n",
      "CONVERSATION COMPLETE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_history': [{'role': 'recruiter',\n",
       "   'content': \"Hey there! I'm Brodie, I focus on Platform Technology and RBCx digital solutions here at RBC. What kind of development work have you been focusing on lately, maybe specifically within the PHP or WordPress space?\"},\n",
       "  {'role': 'candidate',\n",
       "   'content': 'Nice to meet you, Brodie! I’m actually on the AI team here at RBC right now, focusing on building multi-agent systems and intelligent automation with FastAPI. While I have intermediate experience with PHP, I’ve been leaning more into custom AI architectures and scalable backend solutions lately rather than the WordPress space.'},\n",
       "  {'role': 'recruiter',\n",
       "   'content': 'That AI work sounds fascinating, especially with FastAPI. For this specific role at RBCx, we’re really focused on the intersection of high-scale WordPress VIP and frontend excellence. How much experience do you have translating Figma designs into responsive, WCAG-compliant interfaces?'},\n",
       "  {'role': 'candidate',\n",
       "   'content': \"I use Figma regularly to architect the UI for my projects like Rezzy and Viralens before building them out in React or Vue. I'm very comfortable translating designs into responsive, production-ready interfaces, and I always prioritize accessibility and modern web standards in my frontend work.\"},\n",
       "  {'role': 'recruiter',\n",
       "   'content': \"Good to hear you're comfortable with Figma and accessibility. Since this role is heavily centered on WordPress VIP, have you worked with high-scale PHP architectures or custom VIP-compatible themes before?\"},\n",
       "  {'role': 'candidate',\n",
       "   'content': \"I haven't worked with WordPress VIP specifically, but I have a solid foundation in PHP from building custom full-stack solutions. Most of my recent high-scale architecture work has focused on FastAPI and MongoDB for my SaaS projects and enterprise AI systems here at RBC.\"},\n",
       "  {'role': 'recruiter',\n",
       "   'content': 'I appreciate the transparency on the VIP side. Since the RBCx team relies heavily on Git, Jenkins, and CI/CD for our deployments, how have you integrated those DevOps practices into your current AI or SaaS workflows?'},\n",
       "  {'role': 'candidate',\n",
       "   'content': \"I use Git and GitHub Actions daily to manage automated deployments for my SaaS projects like Rezzy. At RBC, I'm already well-integrated into our enterprise CI/CD pipelines, using Jenkins and Docker to ensure our AI services are stable and production-ready.\"},\n",
       "  {'role': 'recruiter',\n",
       "   'content': \"That's a huge plus that you're already familiar with our enterprise Jenkins and Docker environment. Since we use Tailwind CSS heavily for our frontend architecture, have you worked with that much, and how do you usually handle troubleshooting RESTful API integrations?\"},\n",
       "  {'role': 'candidate',\n",
       "   'content': 'I used Tailwind CSS to build out the entire frontend for Rezzy, so I’m very comfortable with that utility-first approach. For troubleshooting APIs, I typically use Postman for manual testing and set up detailed logging in FastAPI to quickly isolate any issues in the data flow.'},\n",
       "  {'role': 'recruiter',\n",
       "   'content': \"I really appreciate the insight into your background; you've clearly got a strong technical foundation in AI and modern frontend tools. While your DevOps and Tailwind skills are spot on, we're specifically looking for deep expertise in WordPress VIP and high-scale PHP for this particular squad.\"}],\n",
       " 'final_evaluation': \"1. Minimum 4 years PHP/JS/WP VIP: ✗ (Intermediate PHP, no VIP experience)\\n2. Figma/Tailwind: ✓ (Regularly uses Figma and built Rezzy with Tailwind)\\n3. WCAG AA: ✓ (Prioritizes accessibility and modern standards)\\n4. RESTful API: ✓ (Uses Postman and logging for troubleshooting)\\n5. DevOps: ✓ (Already using RBC's Jenkins/Docker/Git pipelines)\\n6. UI/UX Translation: ✓ (Architects UI in Figma before building)\\n7. Clean code: ✓ (Follows best practices in enterprise environment)\\n8. Problem-solving: ✓ (Strategic approach to API data flow)\\n9. Reusable PHP templates: ✗ (Focus is on React/Vue/FastAPI)\\n10. CRM: ? (Not confirmed)\\n11. Collaborative: ✓ (Currently working on RBC AI team)\\n12. Passion: ✓ (Active in building side projects like Rezzy and Viralens)\\n\\nRating: 6/10\\nDecision: NOT A FIT. While the candidate is a highly skilled engineer with excellent DevOps and frontend experience, they lack the specific deep expertise in WordPress VIP and high-scale PHP required for this role. Their current trajectory in AI and FastAPI makes them a better fit for other RBC Platform roles rather than this specific WordPress-centric position.\",\n",
       " 'total_turns': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recruiter = RecruiterAgent(recruiter_profile, llm)\n",
    "candidate = CandidateAgent(candidate_profile, llm)\n",
    "orchestrator = ConversationOrchestrator(recruiter, candidate)\n",
    "\n",
    "result = await orchestrator.run_conversation(max_turns=8)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980f272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
